{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBydR4pQt-Oo"
      },
      "source": [
        "Image Classification using Azure AI Vision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9f0lr2uouKha"
      },
      "source": [
        "Step 1: Firstly you should have the \"Azure AI Services\" resource in your Azure resource group, and from this resource you should have the Azure Keys and Endpoints (For the above )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EtpHxqOBt864",
        "outputId": "2c8c3fc8-69d5-4422-ecb8-788f89c2a5b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: Could not find a version that satisfies the requirement azure-ai-vision-imageanalysis==1.0.0b6 (from versions: 1.0.0b1, 1.0.0b2, 1.0.0b3)\n",
            "ERROR: No matching distribution found for azure-ai-vision-imageanalysis==1.0.0b6\n"
          ]
        }
      ],
      "source": [
        "pip install azure-ai-vision-imageanalysis==1.0.0b1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: load_dotenv in c:\\python311\\lib\\site-packages (0.1.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: Could not find a version that satisfies the requirement PIL (from versions: none)\n",
            "ERROR: No matching distribution found for PIL\n"
          ]
        }
      ],
      "source": [
        "pip install load_dotenv PIL matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "4LbPCGOavZOR"
      },
      "outputs": [],
      "source": [
        "## declare the required variables\n",
        "azure_ai_services_endpoint = \"https://azureaiocrserv.cognitiveservices.azure.com/\"\n",
        "azure_ai_services_key= 'fbad8fa8c3774831a9d1345d3375cd55'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Step 2: Import Necessary Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "KUfdSWm3vQ_N"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'PIL'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[19], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image, ImageDraw\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pyplot \u001b[38;5;28;01mas\u001b[39;00m plt\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Import Azure AI Vision client libraries\u001b[39;00m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'PIL'"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "import time\n",
        "from PIL import Image, ImageDraw\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# Import Azure AI Vision client libraries\n",
        "from azure.ai.vision.imageanalysis import ImageAnalysisClient\n",
        "from azure.ai.vision.imageanalysis.models import VisualFeatures\n",
        "from azure.core.credentials import AzureKeyCredential"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Step 3: Load Configuration Settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qc4opkjbHBMD",
        "outputId": "87152560-56c4-4d9f-f3ab-25f1ee410aab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Image saved to Google Drive: /content/drive/My Drive/downloaded_image.jpg\n"
          ]
        }
      ],
      "source": [
        "# Load configuration settings from .env file\n",
        "load_dotenv()\n",
        "ai_endpoint = azure_ai_services_endpoint\n",
        "ai_key = azure_ai_services_key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Step 4: Authenticate Azure AI Vision Client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Authenticate Azure AI Vision client\n",
        "cv_client = ImageAnalysisClient(\n",
        "    endpoint=ai_endpoint,\n",
        "    credential=AzureKeyCredential(ai_key)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Step 5: Define Main Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "ltOVmGWMH92C"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "    global cv_client\n",
        "    try:\n",
        "        image_file = os.path.join('images', 'Note.jpg')\n",
        "        GetTextRead(image_file)\n",
        "    except Exception as ex:\n",
        "        print(ex)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Step 6: Define GetTextRead Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "-K2Zr5vbMeWh"
      },
      "outputs": [],
      "source": [
        "def GetTextRead(image_file):\n",
        "    print('\\n')\n",
        "    # Open image file\n",
        "    with open(image_file, \"rb\") as f:\n",
        "        image_data = f.read()\n",
        "    \n",
        "    # Use Analyze image function to read text in image\n",
        "    result = cv_client.analyze(\n",
        "        image_data=image_data,\n",
        "        visual_features=[VisualFeatures.READ]\n",
        "    )\n",
        "    \n",
        "    # Display the image and overlay it with the extracted text\n",
        "    if result.read is not None:\n",
        "        print(\"\\nText:\")\n",
        "        # Prepare image for drawing\n",
        "        image = Image.open(image_file)\n",
        "        fig = plt.figure(figsize=(image.width/100, image.height/100))\n",
        "        plt.axis('off')\n",
        "        draw = ImageDraw.Draw(image)\n",
        "        color = 'cyan'\n",
        "        \n",
        "        for line in result.read.blocks[0].lines:\n",
        "            # Return the text detected in the image\n",
        "            print(f\"{line.text}\")\n",
        "            drawLinePolygon = True\n",
        "            r = line.bounding_polygon\n",
        "            bounding_polygon = ((r[0].x, r[0].y), (r[1].x, r[1].y), (r[2].x, r[2].y), (r[3].x, r[3].y))\n",
        "            \n",
        "            # Return the position bounding box around each line\n",
        "            print(\" Bounding Polygon: {}\".format(bounding_polygon))\n",
        "            \n",
        "            # Return each word detected in the image and the position bounding box around each word with the confidence level of each word\n",
        "            for word in line.words:\n",
        "                r = word.bounding_polygon\n",
        "                bounding_polygon = ((r[0].x, r[0].y), (r[1].x, r[1].y), (r[2].x, r[2].y), (r[3].x, r[3].y))\n",
        "                print(f\"    Word: '{word.text}', Bounding Polygon: {bounding_polygon}, Confidence: {word.confidence:.4f}\")\n",
        "                \n",
        "                # Draw word bounding polygon\n",
        "                drawLinePolygon = False\n",
        "                draw.polygon(bounding_polygon, outline=color, width=3)\n",
        "            \n",
        "            # Draw line bounding polygon\n",
        "            if drawLinePolygon:\n",
        "                draw.polygon(bounding_polygon, outline=color, width=3)\n",
        "        \n",
        "        # Save image\n",
        "        plt.imshow(image)\n",
        "        plt.tight_layout(pad=0)\n",
        "        outputfile = 'text.jpg'\n",
        "        fig.savefig(outputfile)\n",
        "        print('\\n  Results saved in', outputfile)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Step 7: Run Main Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "AyeKNBwGMide"
      },
      "outputs": [],
      "source": [
        "main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRbmu0mNMkqS",
        "outputId": "d75be2a7-f959-47c0-d35a-4a5069378936"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: '-f'\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O6K7hYFAQqgr"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
